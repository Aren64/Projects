{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f229ffd-789c-4f6d-b7a2-b180a1339122",
   "metadata": {},
   "source": [
    "# Risky Biscuts Final Project\n",
    "\n",
    "Group Members: <br>\n",
    "Alexandria LaBatte, <br>\n",
    "Ernest Elizondo, <br>\n",
    "Rebecca Garcia <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe29c2e-24c4-4477-8ce8-68909fe08452",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc9f833-266b-4283-8be7-a1d7f24f3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "## Load Datasets\n",
    "\n",
    "X_txt_train = []\n",
    "y_train = []\n",
    "X_txt_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load train dataset\n",
    "with open(\"train.tsv\", encoding = 'UTF-8') as fileTrain:\n",
    "    readerTrain = csv.reader(fileTrain, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in readerTrain:\n",
    "        X_txt_train.append(row[1])\n",
    "        y_train.append(row[2])\n",
    "\n",
    "fileTrain.close()\n",
    "\n",
    "# Load test dataset\n",
    "with open(\"test.tsv\", encoding = 'UTF-8') as fileTest:\n",
    "    readerTest = csv.reader(fileTest, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in readerTest:\n",
    "        X_txt_test.append(row[1])\n",
    "        y_test.append(row[2])\n",
    "\n",
    "fileTest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0aaffaa-9b2f-4e14-a0ca-0c28eec7c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Tweet: @USER She should ask a few native Americans what their take on this is.\n",
      "Ground-Truth Class: UNT\n",
      "# 2 Tweet: @USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
      "Ground-Truth Class: TIN\n",
      "# 3 Tweet: Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "Ground-Truth Class: NOT\n",
      "# 4 Tweet: @USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
      "Ground-Truth Class: UNT\n",
      "# 5 Tweet: @USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
      "Ground-Truth Class: NOT\n",
      "# 6 Tweet: @USER Liberals are all Kookoo !!!\n",
      "Ground-Truth Class: TIN\n",
      "# 7 Tweet: @USER @USER Oh noes! Tough shit.\n",
      "Ground-Truth Class: UNT\n",
      "# 8 Tweet: @USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
      "Ground-Truth Class: TIN\n",
      "# 9 Tweet: @USER Buy more icecream!!!\n",
      "Ground-Truth Class: NOT\n",
      "# 10 Tweet: @USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
      "Ground-Truth Class: TIN\n",
      "# 11 Tweet: @USER @USER @USER It’s not my fault you support gun control\n",
      "Ground-Truth Class: NOT\n",
      "# 12 Tweet: @USER What’s the difference between #Kavanaugh and @USER   One of these men admitted to groping a 15 year old girl years ago.  The other is going to be #confirmed to the SCJ   #DemsareFrauds #DemsAreDone   #WalkAwayDemocrats2018 #redwave #VoteRedSaveAmerica #trumptrain #MAGA URL\n",
      "Ground-Truth Class: NOT\n",
      "# 13 Tweet: @USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL\n",
      "Ground-Truth Class: TIN\n",
      "# 14 Tweet: @USER @USER @USER It should scare every American!  She is playing Hockey with a warped puck!\n",
      "Ground-Truth Class: NOT\n",
      "# 15 Tweet: @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER I like my soda like I like my boarders with a lot of ICE.\n",
      "Ground-Truth Class: NOT\n",
      "# 16 Tweet: @USER you are also the king of taste\n",
      "Ground-Truth Class: NOT\n",
      "# 17 Tweet: #MAGA @USER  🎶 Sing like no one is listening  ♥️ Love like you've never been hurt  ✔️ Vote GOP when no one is watching  🙉  And don't listen to Liberals' dirt URL\n",
      "Ground-Truth Class: NOT\n",
      "# 18 Tweet: 5/5: @USER The time is right for this House to respond to the concerns of all Canadians. Four out of five Canadians support stronger gun control and with good reason.” #guncontrol #cdnpoli #cdnhist\"\n",
      "Ground-Truth Class: NOT\n",
      "# 19 Tweet: @USER Besides Jax’s mom and maybe Ope he is hands down my favorite he’s like the only good person on the show 😂\n",
      "Ground-Truth Class: NOT\n",
      "# 20 Tweet: @USER @USER @USER gun control! That is all these kids are asking for!\n",
      "Ground-Truth Class: TIN\n"
     ]
    }
   ],
   "source": [
    "num_tweets = 0\n",
    "for text, y  in zip(X_txt_train, y_train):\n",
    "    print('#', num_tweets + 1, \"Tweet: {}\".format(text))\n",
    "    #print(\"Tweet: {}\".format(text))\n",
    "    print(\"Ground-Truth Class: {}\".format(y))\n",
    "    \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d13f3-ec0c-4503-8547-ae670efa4023",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad8b36-b2c0-4820-b233-7a3ec945f808",
   "metadata": {},
   "source": [
    "#### Feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c24e11-c906-41d2-9ba0-ca0f6f14f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# regex to match '.', '!', '?'\n",
    "def cnt(x):\n",
    "    result = re.findall(r'(\\.{3}|\\!{3}|\\?{3})', x)\n",
    "    if len(result) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2293f5b-01dd-47e8-96c7-b5cd8e7e2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing RegEx\n",
    "#myString = \"omg!!!\"\n",
    "#cnt(myString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaa8ca9-a586-4a0d-8654-90ee075410cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_txt_train\n",
    "X_train_exc_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_exc_features.append([cnt(z)])\n",
    "#X_train_exc_features\n",
    "\n",
    "\n",
    "# for X_txt_test\n",
    "X_test_exc_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_exc_features.append([cnt(n)])\n",
    "#X_test_exc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fc32c6-03b6-4e84-b017-ea088c4ba50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing it here \n",
    "import numpy as np\n",
    "\n",
    "exc_matrix = np.array(X_train_exc_features)\n",
    "exc_matrix\n",
    "#exc_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e748678-466c-4e2e-9043-594b406dab91",
   "metadata": {},
   "source": [
    "#### Feature set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bfdf55-73bb-4f82-8944-db862736846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [4],\n",
       "       [1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pronouns = ['you','your','yours','he','his','she','it','they','her',\n",
    "            'hers','them','theirs',\"you\\'re\",\"she\\'s\",\"he\\'s\",'these']\n",
    "\n",
    "def targeted(string):\n",
    "    tgt=0\n",
    "    for word in string.lower().split():\n",
    "            if word in pronouns:\n",
    "                tgt+=1 # would it be tgt += 1?\n",
    "    return tgt\n",
    "\n",
    "X_train_tgt_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_tgt_features.append([targeted(z)])\n",
    "\n",
    "X_test_tgt_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_tgt_features.append([targeted(n)])\n",
    "    \n",
    "tgt_matrix = np.array(X_train_tgt_features)\n",
    "tgt_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd675c2-b1c5-4fb8-b7a5-bf1d9f7fefa0",
   "metadata": {},
   "source": [
    "#### Feature set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175437fb-47a6-4e87-8de9-8959b90e2526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word classifier class\n",
    "class WordClassifier():\n",
    "    def __init__(self):\n",
    "        self.badwords = set()\n",
    "        with open('badwords.txt') as file:\n",
    "            for row in file:\n",
    "                self.badwords.add(row.strip())\n",
    "\n",
    "                \n",
    "    def bad(self, string):\n",
    "        bdwd=0\n",
    "        for word in string.lower().split():\n",
    "            if word in self.badwords:\n",
    "                bdwd+=1 # bdwd += 1 ?\n",
    "        return bdwd\n",
    "    \n",
    "wordClass = WordClassifier()\n",
    "\n",
    "X_train_bdwdd_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_bdwdd_features.append([wordClass.bad(z)])\n",
    "\n",
    "X_test_bdwdd_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_bdwdd_features.append([wordClass.bad(n)])\n",
    "    \n",
    "bdwd_matrix = np.array(X_train_bdwdd_features)\n",
    "bdwd_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d9c26-f675-4bf6-87c7-086600d0dd68",
   "metadata": {},
   "source": [
    "## Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4348382e-c5e2-4b7b-8dc2-eccffe11b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 16829)\n",
      "['ass' 'bitch' 'bullshit' 'console' 'crap' 'crazy' 'disgusting' 'fuck'\n",
      " 'fuckin' 'fucking' 'he' 'idiot' 'liar' 'racist' 'sex' 'shit' 'stupid'\n",
      " 'the' 'user' 'your']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "X_matrix = vec.fit_transform(X_txt_train)\n",
    "\n",
    "print(X_matrix.shape)\n",
    "\n",
    "skb = SelectKBest(chi2, k=20).fit(X_matrix, y_train)\n",
    "\n",
    "feature_imp = np.array(vec.get_feature_names())\n",
    "\n",
    "print(feature_imp[skb.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a942a-9644-4c71-ab6e-357510607678",
   "metadata": {},
   "source": [
    "## Draft model w/ no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df306703-88ba-4904-a32e-06032281b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.4765\n",
      "Precision: 0.2379\n",
      "Recall: 0.3333\n",
      "F1: 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train = vec.fit_transform(X_txt_train) \n",
    "X_test = vec.transform(X_txt_test) \n",
    "\n",
    "linSVC = LinearSVC()\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "clf = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "validation_score = clf.best_score_ \n",
    "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
    "\n",
    "svm_test_predictions = clf.predict(X_test)  \n",
    "\n",
    "precision = precision_score(svm_test_predictions, y_test, average = \"macro\") \n",
    "recall = recall_score(svm_test_predictions, y_test, average = \"macro\")\n",
    "f1 = f1_score(svm_test_predictions, y_test, average = \"macro\")\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1743d-6030-4dea-839b-e6dfd0edbf05",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4688555a-1a10-49c6-bb24-7f1205babe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf1.fit(X_train_exc, y_train)\n",
    "clf2.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc74e1-d11b-4862-a96f-be766f64d3c6",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5f127b-2fdc-4bbd-9544-569cd11c842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4757\n",
      "Validation F1_micro: 0.7315\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2378\n",
      "Recall: 0.3333\n",
      "F1: 0.2776\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7776\n",
      "Recall: 0.7776\n",
      "F1: 0.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf1.predict(X_test_exc)\n",
    "svm_test_predictions2 = clf2.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2fbdf-605f-4af5-b78b-51efffd928e7",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb666df2-1e22-4e02-a1fe-fd5e39215707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_tgt1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf_tgt2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf_tgt1.fit(X_train_tgt, y_train)\n",
    "clf_tgt2.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576e8ed-2dfc-495f-98ba-6710caa12b8f",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "218483df-e7c6-4d00-9bf6-713d70f4dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4769\n",
      "Validation F1_micro: 0.7304\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2378\n",
      "Recall: 0.3333\n",
      "F1: 0.2776\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7753\n",
      "Recall: 0.7753\n",
      "F1: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_tgt1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_tgt2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf_tgt1.predict(X_test_tgt)\n",
    "svm_test_predictions2 = clf_tgt2.predict(X_test_tgt)\n",
    "\n",
    "#print(classification_report(y_test, svm_test_predictions))\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548b0ec-c802-42f6-aa79-0e5e6474e483",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62932e15-7852-43ff-90ba-1c48add88749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_bdwd1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf_bdwd2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf_bdwd1.fit(X_train_bdwd, y_train)\n",
    "clf_bdwd2.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5daae-1b54-4e8e-a7a1-29ac59d4d346",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8aaa78-3799-43cc-bc6e-26d4d4fc3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4809\n",
      "Validation F1_micro: 0.7316\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2379\n",
      "Recall: 0.3333\n",
      "F1: 0.2777\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7753\n",
      "Recall: 0.7753\n",
      "F1: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_bdwd1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_bdwd2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf_bdwd1.predict(X_test_bdwd)\n",
    "svm_test_predictions2 = clf_bdwd2.predict(X_test_bdwd)\n",
    "\n",
    "#print(classification_report(y_test, svm_test_predictions))\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd499a52-c16f-4765-9086-d90bb403f4e4",
   "metadata": {},
   "source": [
    "## RandomForest with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a575054-a738-4ab4-8556-e6314574c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1exc = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2exc = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1exc.fit(X_train_exc, y_train)\n",
    "clf_rf2exc.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a3b2-bfa3-4462-a902-5afbcd97988f",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2312e6b-8faf-4f44-9a02-4db3cf3efbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4689\n",
      "Validation F1_micro: 0.7338\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2871\n",
      "Recall: 0.3333\n",
      "F1: 0.3085\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8614\n",
      "Recall: 0.8614\n",
      "F1: 0.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1exc.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2exc.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1exc.predict(X_test_exc)\n",
    "preds2 = clf_rf2exc.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535bb14-a6e0-4632-8362-6d94b4e2bb00",
   "metadata": {},
   "source": [
    "## RandomForest with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4809790e-7412-4720-9d92-a9d59024afe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# recommend n_estimators and criterion\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1tgt = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2tgt = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1tgt.fit(X_train_tgt, y_train)\n",
    "clf_rf2tgt.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce3939-4736-4420-a3b6-8bef415df15b",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1faa7fca-9029-4b82-8e20-9aee13667c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4689\n",
      "Validation F1_micro: 0.7320\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2902\n",
      "Recall: 0.3333\n",
      "F1: 0.3102\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8705\n",
      "Recall: 0.8705\n",
      "F1: 0.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1tgt.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2tgt.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1tgt.predict(X_test_tgt)\n",
    "preds2 = clf_rf2tgt.predict(X_test_tgt)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c2261-dfd0-4f51-9f92-92161109bdcf",
   "metadata": {},
   "source": [
    "## RandomForest with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94d8848b-6c4a-4acb-b338-36bf5ab5480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# recommend n_estimators and criterion\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1bdwd = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2bdwd = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1bdwd.fit(X_train_bdwd, y_train)\n",
    "clf_rf2bdwd.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5099-6dd4-412e-8f74-456906304a7c",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96a98a95-b368-4975-84dd-39e854d4f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4739\n",
      "Validation F1_micro: 0.7385\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2807\n",
      "Recall: 0.3333\n",
      "F1: 0.3048\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8418\n",
      "Recall: 0.8418\n",
      "F1: 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1bdwd.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2bdwd.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1bdwd.predict(X_test_bdwd)\n",
    "preds2 = clf_rf2bdwd.predict(X_test_bdwd)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95ea984a-42e6-40fe-84ff-7bb6ef01a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test.tsv',\"r\", encoding=\"UTF-8\") as source:\n",
    "    reader= csv.reader(source, delimiter='\\t')\n",
    "    with open('Risky_Biscuits_test_pred.tsv', 'w', encoding=\"UTF-8\") as result:\n",
    "        writer=csv.writer(result, delimiter='\\t')\n",
    "        for row,i in zip(reader,preds2):\n",
    "            row[2]=i\n",
    "            #print(row)\n",
    "            writer.writerows([row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d4080-3735-4d95-8077-9e1d236a86dc",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffbf80f4-ff86-483e-ab7f-aee777e9d628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1 = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2 = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1.fit(X_train_exc, y_train)\n",
    "clf_dt2.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0feb8-7373-41eb-a483-49ea0a4a356d",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22e71052-e9fa-486f-adb4-78279260217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4629\n",
      "Validation F1_micro: 0.6848\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2407\n",
      "Recall: 0.3333\n",
      "F1: 0.2795\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7221\n",
      "Recall: 0.7221\n",
      "F1: 0.7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1.predict(X_test_exc)\n",
    "preds2 = clf_dt2.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82198b14-c3f7-4c61-9d3c-22fcbee50f63",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2baf21c4-87ea-41ca-9644-fdd2ba2719bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1tgt = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2tgt = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1tgt.fit(X_train_tgt, y_train)\n",
    "clf_dt2tgt.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6466a-e3d0-4795-b23d-d8ecb754644b",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48f9e948-141c-49aa-922b-226ff24de43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4688\n",
      "Validation F1_micro: 0.6875\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2424\n",
      "Recall: 0.3333\n",
      "F1: 0.2807\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7273\n",
      "Recall: 0.7273\n",
      "F1: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1tgt.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2tgt.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1tgt.predict(X_test_tgt)\n",
    "preds2 = clf_dt2tgt.predict(X_test_tgt)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f1d46-0b9e-4bb8-8269-833a9cabef09",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e665eea-d7e4-4d24-8f62-34db537b3dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1bdwd = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2bdwd = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1bdwd.fit(X_train_bdwd, y_train)\n",
    "clf_dt2bdwd.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c32cc-dafa-403b-b82b-97ead4d3fbf9",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "145a0443-2db0-4500-b647-985fb0240a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4653\n",
      "Validation F1_micro: 0.6820\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2355\n",
      "Recall: 0.3333\n",
      "F1: 0.2760\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7119\n",
      "Recall: 0.7119\n",
      "F1: 0.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1bdwd.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2bdwd.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1bdwd.predict(X_test_bdwd)\n",
    "preds2 = clf_dt2bdwd.predict(X_test_bdwd)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e171956-22f4-40d8-aed4-5c9d01f258d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_pred = cross_val_predict(clf, X_train_exc, y_train, cv=3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(clf_rf1tgt, X_train_tgt, y_train, scoring=\"f1_macro\", cv=3))\n",
    "print(cross_val_score(clf_rf1tgt, X_train_tgt, y_train, scoring=\"f1_micro\", cv=3))\n",
    "\n",
    "#train, validation = train_test_split(data, test_size=0.50, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a62c0-86dc-4bf8-a782-53b5b6503306",
   "metadata": {},
   "source": [
    "## Recode Test.txt Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b7a93-113e-403a-a011-de6742546dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test.tsv',\"r\", encoding=\"UTF-8\") as source:\n",
    "    reader= csv.reader(source, delimiter='\\t')\n",
    "    with open('test_pred.tsv', 'w', encoding=\"UTF-8\") as result:\n",
    "        writer=csv.writer(result, delimiter='\\t')\n",
    "        for row,i in zip(reader,preds2):\n",
    "            row[2]=i\n",
    "            #print(row)\n",
    "            writer.writerows([row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
