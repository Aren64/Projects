{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f229ffd-789c-4f6d-b7a2-b180a1339122",
   "metadata": {},
   "source": [
    "# Risky Biscuts Final Project\n",
    "\n",
    "Group Members: <br>\n",
    "Alexandria LaBatte, <br>\n",
    "Ernest Elizondo, <br>\n",
    "Rebecca Garcia <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe29c2e-24c4-4477-8ce8-68909fe08452",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc9f833-266b-4283-8be7-a1d7f24f3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "## Load Datasets\n",
    "\n",
    "X_txt_train = []\n",
    "y_train = []\n",
    "X_txt_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load train dataset\n",
    "with open(\"train.tsv\", encoding = 'UTF-8') as fileTrain:\n",
    "    readerTrain = csv.reader(fileTrain, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in readerTrain:\n",
    "        X_txt_train.append(row[1])\n",
    "        y_train.append(row[2])\n",
    "\n",
    "fileTrain.close()\n",
    "\n",
    "# Load test dataset\n",
    "with open(\"test.tsv\", encoding = 'UTF-8') as fileTest:\n",
    "    readerTest = csv.reader(fileTest, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in readerTest:\n",
    "        X_txt_test.append(row[1])\n",
    "        y_test.append(row[2])\n",
    "\n",
    "fileTest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0aaffaa-9b2f-4e14-a0ca-0c28eec7c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Tweet: @USER She should ask a few native Americans what their take on this is.\n",
      "Ground-Truth Class: UNT\n",
      "# 2 Tweet: @USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\n",
      "Ground-Truth Class: TIN\n",
      "# 3 Tweet: Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "Ground-Truth Class: NOT\n",
      "# 4 Tweet: @USER Someone should'veTaken\" this piece of shit to a volcano. ðŸ˜‚\"\n",
      "Ground-Truth Class: UNT\n",
      "# 5 Tweet: @USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
      "Ground-Truth Class: NOT\n",
      "# 6 Tweet: @USER Liberals are all Kookoo !!!\n",
      "Ground-Truth Class: TIN\n",
      "# 7 Tweet: @USER @USER Oh noes! Tough shit.\n",
      "Ground-Truth Class: UNT\n",
      "# 8 Tweet: @USER was literally just talking about this lol all mass shootings like that have been set ups. itâ€™s propaganda used to divide us on major issues like gun control and terrorism\n",
      "Ground-Truth Class: TIN\n",
      "# 9 Tweet: @USER Buy more icecream!!!\n",
      "Ground-Truth Class: NOT\n",
      "# 10 Tweet: @USER Canada doesnâ€™t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
      "Ground-Truth Class: TIN\n",
      "# 11 Tweet: @USER @USER @USER Itâ€™s not my fault you support gun control\n",
      "Ground-Truth Class: NOT\n",
      "# 12 Tweet: @USER Whatâ€™s the difference between #Kavanaugh and @USER   One of these men admitted to groping a 15 year old girl years ago.  The other is going to be #confirmed to the SCJ   #DemsareFrauds #DemsAreDone   #WalkAwayDemocrats2018 #redwave #VoteRedSaveAmerica #trumptrain #MAGA URL\n",
      "Ground-Truth Class: NOT\n",
      "# 13 Tweet: @USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL\n",
      "Ground-Truth Class: TIN\n",
      "# 14 Tweet: @USER @USER @USER It should scare every American!  She is playing Hockey with a warped puck!\n",
      "Ground-Truth Class: NOT\n",
      "# 15 Tweet: @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER I like my soda like I like my boarders with a lot of ICE.\n",
      "Ground-Truth Class: NOT\n",
      "# 16 Tweet: @USER you are also the king of taste\n",
      "Ground-Truth Class: NOT\n",
      "# 17 Tweet: #MAGA @USER  ðŸŽ¶ Sing like no one is listening  â™¥ï¸ Love like you've never been hurt  âœ”ï¸ Vote GOP when no one is watching  ðŸ™‰  And don't listen to Liberals' dirt URL\n",
      "Ground-Truth Class: NOT\n",
      "# 18 Tweet: 5/5: @USER The time is right for this House to respond to the concerns of all Canadians. Four out of five Canadians support stronger gun control and with good reason.â€ #guncontrol #cdnpoli #cdnhist\"\n",
      "Ground-Truth Class: NOT\n",
      "# 19 Tweet: @USER Besides Jaxâ€™s mom and maybe Ope he is hands down my favorite heâ€™s like the only good person on the show ðŸ˜‚\n",
      "Ground-Truth Class: NOT\n",
      "# 20 Tweet: @USER @USER @USER gun control! That is all these kids are asking for!\n",
      "Ground-Truth Class: TIN\n"
     ]
    }
   ],
   "source": [
    "num_tweets = 0\n",
    "for text, y  in zip(X_txt_train, y_train):\n",
    "    print('#', num_tweets + 1, \"Tweet: {}\".format(text))\n",
    "    #print(\"Tweet: {}\".format(text))\n",
    "    print(\"Ground-Truth Class: {}\".format(y))\n",
    "    \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d13f3-ec0c-4503-8547-ae670efa4023",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad8b36-b2c0-4820-b233-7a3ec945f808",
   "metadata": {},
   "source": [
    "#### Feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c24e11-c906-41d2-9ba0-ca0f6f14f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# regex to match '.', '!', '?'\n",
    "def cnt(x):\n",
    "    result = re.findall(r'(\\.{3}|\\!{3}|\\?{3})', x)\n",
    "    if len(result) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2293f5b-01dd-47e8-96c7-b5cd8e7e2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing RegEx\n",
    "#myString = \"omg!!!\"\n",
    "#cnt(myString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaa8ca9-a586-4a0d-8654-90ee075410cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_txt_train\n",
    "X_train_exc_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_exc_features.append([cnt(z)])\n",
    "#X_train_exc_features\n",
    "\n",
    "\n",
    "# for X_txt_test\n",
    "X_test_exc_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_exc_features.append([cnt(n)])\n",
    "#X_test_exc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fc32c6-03b6-4e84-b017-ea088c4ba50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing it here \n",
    "import numpy as np\n",
    "\n",
    "exc_matrix = np.array(X_train_exc_features)\n",
    "exc_matrix\n",
    "#exc_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e748678-466c-4e2e-9043-594b406dab91",
   "metadata": {},
   "source": [
    "#### Feature set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bfdf55-73bb-4f82-8944-db862736846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [4],\n",
       "       [1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pronouns = ['you','your','yours','he','his','she','it','they','her',\n",
    "            'hers','them','theirs',\"you\\'re\",\"she\\'s\",\"he\\'s\",'these']\n",
    "\n",
    "def targeted(string):\n",
    "    tgt=0\n",
    "    for word in string.lower().split():\n",
    "            if word in pronouns:\n",
    "                tgt+=1 # would it be tgt += 1?\n",
    "    return tgt\n",
    "\n",
    "X_train_tgt_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_tgt_features.append([targeted(z)])\n",
    "\n",
    "X_test_tgt_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_tgt_features.append([targeted(n)])\n",
    "    \n",
    "tgt_matrix = np.array(X_train_tgt_features)\n",
    "tgt_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd675c2-b1c5-4fb8-b7a5-bf1d9f7fefa0",
   "metadata": {},
   "source": [
    "#### Feature set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175437fb-47a6-4e87-8de9-8959b90e2526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word classifier class\n",
    "class WordClassifier():\n",
    "    def __init__(self):\n",
    "        self.badwords = set()\n",
    "        with open('badwords.txt') as file:\n",
    "            for row in file:\n",
    "                self.badwords.add(row.strip())\n",
    "\n",
    "                \n",
    "    def bad(self, string):\n",
    "        bdwd=0\n",
    "        for word in string.lower().split():\n",
    "            if word in self.badwords:\n",
    "                bdwd+=1 # bdwd += 1 ?\n",
    "        return bdwd\n",
    "    \n",
    "wordClass = WordClassifier()\n",
    "\n",
    "X_train_bdwdd_features = []\n",
    "for z in X_txt_train:\n",
    "    X_train_bdwdd_features.append([wordClass.bad(z)])\n",
    "\n",
    "X_test_bdwdd_features = []\n",
    "for n in X_txt_test:\n",
    "    X_test_bdwdd_features.append([wordClass.bad(n)])\n",
    "    \n",
    "bdwd_matrix = np.array(X_train_bdwdd_features)\n",
    "bdwd_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d9c26-f675-4bf6-87c7-086600d0dd68",
   "metadata": {},
   "source": [
    "## Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4348382e-c5e2-4b7b-8dc2-eccffe11b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 16829)\n",
      "['ass' 'bitch' 'bullshit' 'console' 'crap' 'crazy' 'disgusting' 'fuck'\n",
      " 'fuckin' 'fucking' 'he' 'idiot' 'liar' 'racist' 'sex' 'shit' 'stupid'\n",
      " 'the' 'user' 'your']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "X_matrix = vec.fit_transform(X_txt_train)\n",
    "\n",
    "print(X_matrix.shape)\n",
    "\n",
    "skb = SelectKBest(chi2, k=20).fit(X_matrix, y_train)\n",
    "\n",
    "feature_imp = np.array(vec.get_feature_names())\n",
    "\n",
    "print(feature_imp[skb.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a942a-9644-4c71-ab6e-357510607678",
   "metadata": {},
   "source": [
    "## Draft model w/ no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df306703-88ba-4904-a32e-06032281b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.4765\n",
      "Precision: 0.2379\n",
      "Recall: 0.3333\n",
      "F1: 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train = vec.fit_transform(X_txt_train) \n",
    "X_test = vec.transform(X_txt_test) \n",
    "\n",
    "linSVC = LinearSVC()\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "clf = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "validation_score = clf.best_score_ \n",
    "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
    "\n",
    "svm_test_predictions = clf.predict(X_test)  \n",
    "\n",
    "precision = precision_score(svm_test_predictions, y_test, average = \"macro\") \n",
    "recall = recall_score(svm_test_predictions, y_test, average = \"macro\")\n",
    "f1 = f1_score(svm_test_predictions, y_test, average = \"macro\")\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1743d-6030-4dea-839b-e6dfd0edbf05",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4688555a-1a10-49c6-bb24-7f1205babe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf1.fit(X_train_exc, y_train)\n",
    "clf2.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc74e1-d11b-4862-a96f-be766f64d3c6",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5f127b-2fdc-4bbd-9544-569cd11c842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4757\n",
      "Validation F1_micro: 0.7315\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2378\n",
      "Recall: 0.3333\n",
      "F1: 0.2776\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7776\n",
      "Recall: 0.7776\n",
      "F1: 0.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf1.predict(X_test_exc)\n",
    "svm_test_predictions2 = clf2.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2fbdf-605f-4af5-b78b-51efffd928e7",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb666df2-1e22-4e02-a1fe-fd5e39215707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_tgt1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf_tgt2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf_tgt1.fit(X_train_tgt, y_train)\n",
    "clf_tgt2.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576e8ed-2dfc-495f-98ba-6710caa12b8f",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "218483df-e7c6-4d00-9bf6-713d70f4dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4769\n",
      "Validation F1_micro: 0.7304\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2378\n",
      "Recall: 0.3333\n",
      "F1: 0.2776\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7753\n",
      "Recall: 0.7753\n",
      "F1: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_tgt1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_tgt2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf_tgt1.predict(X_test_tgt)\n",
    "svm_test_predictions2 = clf_tgt2.predict(X_test_tgt)\n",
    "\n",
    "#print(classification_report(y_test, svm_test_predictions))\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548b0ec-c802-42f6-aa79-0e5e6474e483",
   "metadata": {},
   "source": [
    "## LinearSVC with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62932e15-7852-43ff-90ba-1c48add88749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "linSVC = LinearSVC(random_state=42)\n",
    "\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_bdwd1 = GridSearchCV(linSVC, params, scoring ='f1_macro', cv=5)\n",
    "clf_bdwd2 = GridSearchCV(linSVC, params, scoring ='f1_micro', cv=5)\n",
    "\n",
    "clf_bdwd1.fit(X_train_bdwd, y_train)\n",
    "clf_bdwd2.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5daae-1b54-4e8e-a7a1-29ac59d4d346",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8aaa78-3799-43cc-bc6e-26d4d4fc3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4809\n",
      "Validation F1_micro: 0.7316\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2379\n",
      "Recall: 0.3333\n",
      "F1: 0.2777\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7753\n",
      "Recall: 0.7753\n",
      "F1: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_bdwd1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_bdwd2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "svm_test_predictions1 = clf_bdwd1.predict(X_test_bdwd)\n",
    "svm_test_predictions2 = clf_bdwd2.predict(X_test_bdwd)\n",
    "\n",
    "#print(classification_report(y_test, svm_test_predictions))\n",
    "\n",
    "precision1 = precision_score(svm_test_predictions1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(svm_test_predictions1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(svm_test_predictions2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(svm_test_predictions2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd499a52-c16f-4765-9086-d90bb403f4e4",
   "metadata": {},
   "source": [
    "## RandomForest with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a575054-a738-4ab4-8556-e6314574c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1exc = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2exc = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1exc.fit(X_train_exc, y_train)\n",
    "clf_rf2exc.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a3b2-bfa3-4462-a902-5afbcd97988f",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2312e6b-8faf-4f44-9a02-4db3cf3efbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4689\n",
      "Validation F1_micro: 0.7338\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2871\n",
      "Recall: 0.3333\n",
      "F1: 0.3085\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8614\n",
      "Recall: 0.8614\n",
      "F1: 0.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1exc.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2exc.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1exc.predict(X_test_exc)\n",
    "preds2 = clf_rf2exc.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535bb14-a6e0-4632-8362-6d94b4e2bb00",
   "metadata": {},
   "source": [
    "## RandomForest with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4809790e-7412-4720-9d92-a9d59024afe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# recommend n_estimators and criterion\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1tgt = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2tgt = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1tgt.fit(X_train_tgt, y_train)\n",
    "clf_rf2tgt.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce3939-4736-4420-a3b6-8bef415df15b",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1faa7fca-9029-4b82-8e20-9aee13667c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4689\n",
      "Validation F1_micro: 0.7320\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2902\n",
      "Recall: 0.3333\n",
      "F1: 0.3102\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8705\n",
      "Recall: 0.8705\n",
      "F1: 0.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1tgt.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2tgt.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1tgt.predict(X_test_tgt)\n",
    "preds2 = clf_rf2tgt.predict(X_test_tgt)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c2261-dfd0-4f51-9f92-92161109bdcf",
   "metadata": {},
   "source": [
    "## RandomForest with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94d8848b-6c4a-4acb-b338-36bf5ab5480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [10, 50, 100]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# recommend n_estimators and criterion\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_rf1bdwd = GridSearchCV(rf, params, scoring = 'f1_macro', cv=2)\n",
    "clf_rf2bdwd = GridSearchCV(rf, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_rf1bdwd.fit(X_train_bdwd, y_train)\n",
    "clf_rf2bdwd.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5099-6dd4-412e-8f74-456906304a7c",
   "metadata": {},
   "source": [
    "### Evaluate RandomForest Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96a98a95-b368-4975-84dd-39e854d4f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4739\n",
      "Validation F1_micro: 0.7385\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2807\n",
      "Recall: 0.3333\n",
      "F1: 0.3048\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.8418\n",
      "Recall: 0.8418\n",
      "F1: 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_rf1bdwd.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_rf2bdwd.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_rf1bdwd.predict(X_test_bdwd)\n",
    "preds2 = clf_rf2bdwd.predict(X_test_bdwd)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95ea984a-42e6-40fe-84ff-7bb6ef01a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test.tsv',\"r\", encoding=\"UTF-8\") as source:\n",
    "    reader= csv.reader(source, delimiter='\\t')\n",
    "    with open('Risky_Biscuits_test_pred.tsv', 'w', encoding=\"UTF-8\") as result:\n",
    "        writer=csv.writer(result, delimiter='\\t')\n",
    "        for row,i in zip(reader,preds2):\n",
    "            row[2]=i\n",
    "            #print(row)\n",
    "            writer.writerows([row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d4080-3735-4d95-8077-9e1d236a86dc",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffbf80f4-ff86-483e-ab7f-aee777e9d628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_exxc = vec.fit_transform(X_txt_train)\n",
    "X_test_exxc = vec.transform(X_txt_test)\n",
    "\n",
    "arrayTrain = np.array(X_train_exc_features)\n",
    "arrayTest = np.array(X_test_exc_features)\n",
    "\n",
    "X_train_exc = hstack([X_train_exxc, arrayTrain])\n",
    "X_test_exc = hstack([X_test_exxc, arrayTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1 = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2 = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1.fit(X_train_exc, y_train)\n",
    "clf_dt2.fit(X_train_exc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0feb8-7373-41eb-a483-49ea0a4a356d",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22e71052-e9fa-486f-adb4-78279260217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4629\n",
      "Validation F1_micro: 0.6848\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2407\n",
      "Recall: 0.3333\n",
      "F1: 0.2795\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7221\n",
      "Recall: 0.7221\n",
      "F1: 0.7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1.predict(X_test_exc)\n",
    "preds2 = clf_dt2.predict(X_test_exc)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82198b14-c3f7-4c61-9d3c-22fcbee50f63",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2baf21c4-87ea-41ca-9644-fdd2ba2719bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_tggt = vec.fit_transform(X_txt_train)\n",
    "X_test_tggt = vec.transform(X_txt_test)\n",
    "\n",
    "newarrayTrain = np.array(X_train_tgt_features)\n",
    "newarrayTest = np.array(X_test_tgt_features)\n",
    "\n",
    "X_train_tgt = hstack([X_train_tggt, newarrayTrain])\n",
    "X_test_tgt = hstack([X_test_tggt, newarrayTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1tgt = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2tgt = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1tgt.fit(X_train_tgt, y_train)\n",
    "clf_dt2tgt.fit(X_train_tgt, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6466a-e3d0-4795-b23d-d8ecb754644b",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48f9e948-141c-49aa-922b-226ff24de43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4688\n",
      "Validation F1_micro: 0.6875\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2424\n",
      "Recall: 0.3333\n",
      "F1: 0.2807\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7273\n",
      "Recall: 0.7273\n",
      "F1: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1tgt.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2tgt.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1tgt.predict(X_test_tgt)\n",
    "preds2 = clf_dt2tgt.predict(X_test_tgt)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f1d46-0b9e-4bb8-8269-833a9cabef09",
   "metadata": {},
   "source": [
    "## DecisionTree with feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e665eea-d7e4-4d24-8f62-34db537b3dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'min_samples_split': [2, 3, 4]}, scoring='f1_micro')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_bdwdd = vec.fit_transform(X_txt_train)\n",
    "X_test_bdwdd = vec.transform(X_txt_test)\n",
    "\n",
    "arrTrain = np.array(X_train_bdwdd_features)\n",
    "arrTest = np.array(X_test_bdwdd_features)\n",
    "\n",
    "X_train_bdwd = hstack([X_train_bdwdd, arrTrain])\n",
    "X_test_bdwd = hstack([X_test_bdwdd, arrTest])\n",
    "\n",
    "params = {'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# I added two gridsearchcv and fits so we can get both micro and macro\n",
    "\n",
    "clf_dt1bdwd = GridSearchCV(dt, params, scoring = 'f1_macro', cv=2)\n",
    "clf_dt2bdwd = GridSearchCV(dt, params, scoring = 'f1_micro', cv=2)\n",
    "\n",
    "clf_dt1bdwd.fit(X_train_bdwd, y_train)\n",
    "clf_dt2bdwd.fit(X_train_bdwd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c32cc-dafa-403b-b82b-97ead4d3fbf9",
   "metadata": {},
   "source": [
    "### Evaluate DecisionTree Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "145a0443-2db0-4500-b647-985fb0240a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1_macro: 0.4653\n",
      "Validation F1_micro: 0.6820\n",
      "\n",
      "F1 Macro\n",
      "Precision: 0.2355\n",
      "Recall: 0.3333\n",
      "F1: 0.2760\n",
      "\n",
      "F1 Micro\n",
      "Precision: 0.7119\n",
      "Recall: 0.7119\n",
      "F1: 0.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# again I doubled everything so we can get micro and macro scores\n",
    "\n",
    "validation_score1 = clf_dt1bdwd.best_score_ \n",
    "print(\"Validation F1_macro: {:.4f}\".format(validation_score1))\n",
    "\n",
    "validation_score2 = clf_dt2bdwd.best_score_ \n",
    "print(\"Validation F1_micro: {:.4f}\".format(validation_score2))\n",
    "\n",
    "preds1 = clf_dt1bdwd.predict(X_test_bdwd)\n",
    "preds2 = clf_dt2bdwd.predict(X_test_bdwd)\n",
    "\n",
    "precision1 = precision_score(preds1, y_test, average = \"macro\") \n",
    "recall1 = recall_score(preds1, y_test, average = \"macro\")\n",
    "f1_1 = f1_score(preds1, y_test, average = \"macro\")\n",
    "\n",
    "print(\"\\nF1 Macro\")\n",
    "print(\"Precision: {:.4f}\".format(precision1))\n",
    "print(\"Recall: {:.4f}\".format(recall1))\n",
    "print(\"F1: {:.4f}\".format(f1_1))\n",
    "\n",
    "\n",
    "precision2 = precision_score(preds2, y_test, average = \"micro\") \n",
    "recall2 = recall_score(preds2, y_test, average = \"micro\")\n",
    "f1_2 = f1_score(preds2, y_test, average = \"micro\")\n",
    "\n",
    "print(\"\\nF1 Micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision2))\n",
    "print(\"Recall: {:.4f}\".format(recall2))\n",
    "print(\"F1: {:.4f}\".format(f1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e171956-22f4-40d8-aed4-5c9d01f258d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_pred = cross_val_predict(clf, X_train_exc, y_train, cv=3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(clf_rf1tgt, X_train_tgt, y_train, scoring=\"f1_macro\", cv=3))\n",
    "print(cross_val_score(clf_rf1tgt, X_train_tgt, y_train, scoring=\"f1_micro\", cv=3))\n",
    "\n",
    "#train, validation = train_test_split(data, test_size=0.50, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a62c0-86dc-4bf8-a782-53b5b6503306",
   "metadata": {},
   "source": [
    "## Recode Test.txt Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b7a93-113e-403a-a011-de6742546dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test.tsv',\"r\", encoding=\"UTF-8\") as source:\n",
    "    reader= csv.reader(source, delimiter='\\t')\n",
    "    with open('test_pred.tsv', 'w', encoding=\"UTF-8\") as result:\n",
    "        writer=csv.writer(result, delimiter='\\t')\n",
    "        for row,i in zip(reader,preds2):\n",
    "            row[2]=i\n",
    "            #print(row)\n",
    "            writer.writerows([row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
